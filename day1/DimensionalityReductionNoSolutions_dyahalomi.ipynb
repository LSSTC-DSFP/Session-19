{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d90d3986",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Dimensionality Reduction Tutorial\n",
    "\n",
    "### Bryan Scott, CIERA/Northwestern\n",
    "version 0.1, August 2023\n",
    "\n",
    "In this tutorial, we will begin by reading in postage stamp images from the Sloan Digital Sky Survey. The first part of the lesson will then decompose these images into their principle components using both our own implementation of the PCA procedure in numpy, and make use of the scikit-learn PCA implementation. Our learning goals are two fold - to gain familiarity with PCA and to gain experience with scikit-learn on a problem where we can straightforwardly implement our own version of the tools. \n",
    "\n",
    "In the second part of the tutorial, we will apply t-SNE to Cosmos2020 28-band photometry and visualize in 2D the separation of different objects in redshift as a function of their 28D fluxes.\n",
    "\n",
    "The challenge problem asks you to build a SOM from scratch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae8731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d7a40e",
   "metadata": {},
   "source": [
    "## Problem 1: Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c457be51",
   "metadata": {},
   "source": [
    "### Preliminary: Download the images and load them into arrays called images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb43a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the images and labels from file\n",
    "with h5py.File('', 'r') as F: # your path goes here \n",
    "    images = np.array(F['images'])\n",
    "    labels = np.array(F['ans'])\n",
    "\n",
    "# To convert to desirable type\n",
    "labels = labels.astype(np.float32)\n",
    "images = images.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b427dee",
   "metadata": {},
   "source": [
    "### Part 0: A Gentle Introduction to the data\n",
    "\n",
    "The first step in any ML workflow is to 'worry' about the data. First, print out the dimensions of the images and labels arrays. Why does each array have the dimensionality that it does? Write your answer in the provided markdown cell below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0228dd9a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22cc8f30",
   "metadata": {},
   "source": [
    "Now, let's visually inspect our data. In the Wide Field Image Processing session, we have/will cover how to generate false color images from multi-band photometry. For now, we can use the astropy implementation. Given the following help call, fill in the code block below to generate false color images for the first SDSS postage stamp. Do this for object 14001 in the provided h5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d38d8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.visualization import make_lupton_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc0f0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.visualization import make_lupton_rgb\n",
    "\n",
    "i_data = images[14001, :, :, 0] # first band\n",
    "r_data = images[14001, :, :, 1] # second band\n",
    "g_data = images[14001, :, :, 2] # third band\n",
    "\n",
    "rgb = make_lupton_rgb(), # fill this in - what band goes here?\n",
    "                      ), # fill this in - what band goes here?\n",
    "                      ), # fill this in - and finally what band goes here?\n",
    "                      minimum=0, Q=6, stretch=50) # Bonus Q: how does changing these paramters change the images?\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ax.imshow(rgb, origin='lower')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb75dd66",
   "metadata": {},
   "source": [
    "### Visualize individual classes \n",
    "\n",
    "The Galaxy10 dataset consists of the following classes: \n",
    "\n",
    "Galaxy10 dataset (21785 images)\n",
    "- Class 0 (3461 images): Disk, Face-on, No Spiral\n",
    "- Class 1 (6997 images): Smooth, Completely round\n",
    "- Class 2 (6292 images): Smooth, in-between round\n",
    "- Class 3 (394 images): Smooth, Cigar shaped\n",
    "- Class 4 (1534 images): Disk, Edge-on, Rounded Bulge\n",
    "- Class 5 (17 images): Disk, Edge-on, Boxy Bulge\n",
    "- Class 6 (589 images): Disk, Edge-on, No Bulge\n",
    "- Class 7 (1121 images): Disk, Face-on, Tight Spiral\n",
    "- Class 8 (906 images): Disk, Face-on, Medium Spiral\n",
    "- Class 9 (519 images): Disk, Face-on, Loose Spiral\n",
    "\n",
    "Before proceeding, what do you notice about these classes. Why is this potentially problematic? \n",
    "\n",
    "Now use the labels vector to visualize a member of each class: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdf3fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range():\n",
    "    plt.imshow() # what goes here?\n",
    "    plt.title('Class {}'.format(i))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5645ec49",
   "metadata": {},
   "source": [
    "### Part 1: Principal Components and the Singular Value Decomposition\n",
    "\n",
    "Can we distinguish galaxy types based on their PCA components? Let's find out! Let's attempt to distinguish between smooth and round objects in Class 1 from the boxy and edge on spirals in Class 4. Start by using the tools you wrote above to visualize an example from each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be9403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class 1 visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d51e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class 4 visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3073153e",
   "metadata": {},
   "source": [
    "Now perform the singular value decomposition using the numpy implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ed3ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, what does the SVD take as arguments and, in terms of the PCA framework, what does it return? \n",
    "# Answer in the provided markdown cell below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e400cd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adcacec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, you may have noticed that our image array isn't structured in such a way that we can perform PCA \n",
    "# on it directly.\n",
    "# What shape should the image array have, use np.reshape to reshape the array.\n",
    "\n",
    "images_of_class = #fill this in for the class you want to compute the PCA for\n",
    "images_of_class_mean_subtracted = # recenter\n",
    "images_reshape =  # what shape should this have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc8982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the SVD \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe18023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the Principal components\n",
    "\n",
    "h, w = 69, 69\n",
    "\n",
    "def plot_gallery(images, h, w, n_row=3, n_col=4):\n",
    "    \"\"\"Helper function to plot a gallery of portraits \n",
    "    #from sklearn documentation\"\"\"\n",
    "    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=0.01, right=0.99, top=0.90, hspace=0.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "        \n",
    "plot_gallery(Vh, h, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bcb12c",
   "metadata": {},
   "source": [
    "### Part 2: Practicing with the Scikit-learn Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a797997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be6ca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e857846",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = \n",
    "\n",
    "pca = PCA().fit()\n",
    "\n",
    "eigengalaxies = pca.components_.reshape(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e031be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gallery()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cf3e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca.transform() will provide the appropriate weights for each principal component. \n",
    "# write a loop or a vectorized computation to sum over the principal components and reconstruct \n",
    "# an image of a given galaxy (perhaps the one at index 10, or pick your favorite). \n",
    "\n",
    "reconstruction = \n",
    "\n",
    "for i in range():\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d5e667",
   "metadata": {},
   "source": [
    "## Problem 2: t-distributed Stochastic Neighbor Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a10ec3",
   "metadata": {},
   "source": [
    "Begin by reading in the supplied cosmos 2020 28 band photometry. Print out the catalog and some summary statistics. Make sure you understand the structure of the supplied data file, and check that it has been cleaned of anamolous values (for example, -99 is often used as a flag value, and many data files contain NaNs). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfefbe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmos_2020 = pd.read_csv('cosmos_2020_28_band.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632d88da",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmos_2020.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42f145e",
   "metadata": {},
   "source": [
    "For this part, we will use the built in TSNE methods in the sci-kit learn package. These are located in sklearn-manifold (many dimensionality reduction techniques are examples of manifold learning). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf3df4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec63480",
   "metadata": {},
   "source": [
    "Next, define a dictionary object to contain the TSNE object and it's hyperparameters. The one we will focus on, in particular, is the perplexity. For now, set the perplexity to a reasonable value between 5 and 50. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d8abf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tSNE = TSNE(\n",
    "        perplexity = 10,\n",
    "        n_components=2,\n",
    "        n_iter=2000,\n",
    "        n_iter_without_progress=200,\n",
    "        n_jobs=2,\n",
    "        random_state=0,\n",
    "        init = 'pca',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204998cf",
   "metadata": {},
   "source": [
    "Our goal here is to see how well tSNE can visualize class separations between objects at different redshifts. As such, we will need to generate a labels data vector to use with our tSNE embedding. As you may have noticed, the redshift values in the catalog have already been binned for you. As such, the labels are contained in the redshift column of the cosmos 2020 catalog. Define a labels data series. \n",
    "\n",
    "After doing that, you'll want to drop the redshift column from your data vector so that tSNE isn't using redshift as a variable in its distance calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6351c4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = \n",
    "new_data = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1096106",
   "metadata": {},
   "source": [
    "In sklearn, we use the fit_transform method to simultaneously fit and apply the learned transformation to the data. Since this is an unsupervised problem, this is as straightforward as providing the fit_transform method the data and a labels vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bd2cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tSNE_map = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f02e34",
   "metadata": {},
   "source": [
    "We can then plot the 2D representation of the labelled 28D photometric space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ee41e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = \n",
    "colormap = ['r', 'b', 'g', 'y', 'm', 'k']\n",
    "\n",
    "# labels = \n",
    "\n",
    "for i,label in enumerate():\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920fdd41",
   "metadata": {},
   "source": [
    "Finally, repeat this exercise for different values of the perplexity. How does changing the perplexity change your 2D map?\n",
    "\n",
    "What other - perhaps unstated - hyperparameter choice impacts your ability to do the class separation or interpret your 2D map? If this were a problem to come up in your research, how might you use your knowledge of the photometry and galaxy SEDs to improve the class separation in the 2D SNE plane?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582b93f0",
   "metadata": {},
   "source": [
    "## [Optional] Challenge Problem: Implementing your own SOM\n",
    "\n",
    "(Very rough) pseudo code for a SOM implementation is provided below: \n",
    "\n",
    "$\\textit{If you attempt this exercise, please provide feedback as this is intended as a problem for a future session.}$"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f3437087",
   "metadata": {},
   "source": [
    "Convenience functions: \n",
    "\n",
    "distance:\n",
    "    given two data points, compute the distance\n",
    "\n",
    "best_matching_unit:\n",
    "    for a given data point:\n",
    "        Compute all distances to cells in the SOM\n",
    "        update the shortest distance\n",
    "    return shortest distance\n",
    "\n",
    "decay: \n",
    "    for a given step in the training:\n",
    "        adjust neighborhood size and learning rate to ensure convergence\n",
    "\n",
    "Training routine:\n",
    "For each step in the training: \n",
    "    update the hyperparameters (learning_rate, neighborhood size)\n",
    "    Pick a random data point \n",
    "    determine the winning cell in the SOM (closest match to the data)\n",
    "    for all points near the winner, move them closer"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
